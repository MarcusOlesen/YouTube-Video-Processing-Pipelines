{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94c14912",
   "metadata": {},
   "source": [
    "# Visual Feature Analysis Pipeline\n",
    "\n",
    "## Overview\n",
    "This Jupyter notebook implements a comprehensive visual feature extraction pipeline for video analysis. It processes videos by extracting keyframes and analyzing various visual characteristics.\n",
    "\n",
    "### Key Features\n",
    "- **Frame Analysis**:\n",
    "  - Color statistics (warmth, distribution, entropy)\n",
    "  - HSV color space analysis\n",
    "  - Texture features (GLCM, wavelets)\n",
    "  - Image composition metrics\n",
    "- **Object Detection**:\n",
    "  - Face detection\n",
    "  - Person detection\n",
    "  - Hand tracking\n",
    "- **Technical Features**:\n",
    "  - Blur detection\n",
    "  - Edge detection\n",
    "  - Rule of thirds analysis\n",
    "  - Depth of field estimation\n",
    "\n",
    "### Prerequisites\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccc6074",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python\n",
    "!pip install ffmpeg-python\n",
    "!pip install scipy\n",
    "!pip install PyWavelets\n",
    "!pip install scikit-image\n",
    "!pip install pandas\n",
    "!pip install matplotlib\n",
    "!pip install librosa\n",
    "!pip install mediapipe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b241826",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Usage\n",
    "The pipeline processes videos in batches, extracting keyframes at specified intervals and analyzing various visual features. Results are saved to CSV files for further analysis. The processing can be resumed from previous runs using checkpointing.\n",
    "\n",
    "### Technical Notes\n",
    "- Processes videos in blocks of 2,018 files\n",
    "- Supports 10 processing blocks total (20,180 videos)\n",
    "- Saves intermediate results to prevent data loss\n",
    "- Uses multiple computer vision libraries for comprehensive analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e7660a1-025a-4321-bfef-8a9c1cea56c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ffmpeg\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import skew\n",
    "from copy import deepcopy\n",
    "from skimage.feature import local_binary_pattern\n",
    "import librosa\n",
    "import subprocess\n",
    "import json\n",
    "import time\n",
    "import warnings\n",
    "from video_analysis_utils import *\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69c30006-ed7f-4f7b-89e2-014e407f1b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_video(video_id, video_dir, keyframe_dir, keyframe_interval=10, measures=None):\n",
    "    \"\"\" \n",
    "    Extract and analyze keyframes from video.\n",
    "    Output is a dictionary with video_id and mean, sd, and volatility for different measures.\n",
    "    \n",
    "    `measures` is a list of tuples, where each tuple contains:\n",
    "        (measure_name (str), measure_function (function), output_keys (list of str for mean, sd, vol))\n",
    "    \"\"\"\n",
    "    video_measurements = {}\n",
    "    video_measurements['video_id'] = video_id\n",
    "    \n",
    "    # Ensure the output folder path ends with a separator\n",
    "    if not video_dir.endswith(os.sep):\n",
    "        video_dir += os.sep\n",
    "\n",
    "    video_path = video_dir + video_id + '.mp4'\n",
    "\n",
    "    # Extract keyframes to keyframe folder for analysis\n",
    "    nb_keyframes = extract_keyframes(video_path, keyframe_dir, s=keyframe_interval)\n",
    "    \n",
    "    video_measurements['nb_keyframes'] = nb_keyframes\n",
    "\n",
    "    # Default to an empty list if no measures are provided\n",
    "    if measures is None:\n",
    "        measures = []\n",
    "\n",
    "    # Apply each measure\n",
    "    for measure_name, measure_function, output_keys in measures:\n",
    "        # Get measure result (e.g., mean, sd, vol)\n",
    "        measure_values = measure_function(keyframe_dir)\n",
    "        \n",
    "        # Map result to the output keys in the dictionary\n",
    "        for i, key in enumerate(output_keys):\n",
    "            video_measurements[f\"{measure_name}_{key}\"] = measure_values[i]\n",
    "    \n",
    "    ## complicated functions\n",
    "    # color %\n",
    "    results = calculate_color_percentages_statistics(keyframe_dir)\n",
    "    colors = ['black', 'gray', 'white', 'red', 'green', 'blue', 'yellow', 'orange', 'brown', 'pink', 'purple']\n",
    "    statistics = ['mean', 'sd', 'vol']\n",
    "    for i, col in enumerate(colors):\n",
    "        for j, stat in enumerate(statistics):\n",
    "            video_measurements[f\"{col}%_{stat}\"] = results[j][i]\n",
    "\n",
    "    # HSV stats\n",
    "    results = calculate_hsv_statistics(keyframe_dir)\n",
    "    output_keys = [\"mean_avg_value\", \"mean_avg_saturation\", \"mean_sd_value\", \"mean_sd_saturation\",\n",
    "                   \"sd_avg_value\", \"sd_avg_saturation\", \"sd_sd_value\", \"sd_sd_saturation\", \n",
    "                    \"vol_avg_value\", \"vol_avg_saturation\", \"vol_sd_value\", \"vol_sd_saturation\"]\n",
    "    for i, key in enumerate(output_keys):\n",
    "        video_measurements[f\"{key}\"] = results[i]\n",
    "    results = calculate_hue_circular_variance_statistics(keyframe_dir)\n",
    "    output_keys = [\"mean_circular_var_hue\", \"sd_circular_var_hue\", \"vol_circular_var_hue\"]\n",
    "    for i, key in enumerate(output_keys):\n",
    "        video_measurements[f\"{key}\"] = results[i]\n",
    "\n",
    "    # avg wavelet value\n",
    "    results = calculate_hsv_wavelet_mean_statistics(keyframe_dir)\n",
    "    keys = ['hue', 'saturation', 'value']\n",
    "    statistics = ['mean', 'sd', 'vol']\n",
    "    for i, key in enumerate(keys):\n",
    "        for j, stat in enumerate(statistics):\n",
    "            video_measurements[f\"{key}_avg_wavelet_{stat}\"] = results[j][i]\n",
    "\n",
    "    # HSV (GLCM) statistics\n",
    "    results = calculate_glcm_statistics(keyframe_dir)\n",
    "    keys = ['hue', 'saturation', 'value']\n",
    "    features = [\"contrast\", \"correlation\", \"energy\", \"homogeneity\"]\n",
    "    statistics = ['mean', 'sd', 'vol']\n",
    "    for j, key in enumerate(keys):\n",
    "        for i, stat in enumerate(statistics):\n",
    "            for k, feature in enumerate(features):\n",
    "                video_measurements[f\"{key}_{feature}_{stat}\"] = results[i][j][k]\n",
    "\n",
    "    # Low deapth of field (DOF) \n",
    "    results = calculate_low_dof_statistics(keyframe_dir)\n",
    "    keys = ['hue', 'saturation', 'value']\n",
    "    statistics = ['mean', 'sd', 'vol']\n",
    "    for i, key in enumerate(keys):\n",
    "        for j, stat in enumerate(statistics):\n",
    "            video_measurements[f\"{key}_low_dof_{stat}\"] = results[j][i]\n",
    "\n",
    "    # Rule of thirds \n",
    "    results = calculate_rule_of_thirds_statistics(keyframe_dir)\n",
    "    keys = ['saturation', 'value']\n",
    "    statistics = ['mean', 'sd', 'vol']\n",
    "    for j, key in enumerate(keys):\n",
    "        for i, stat in enumerate(statistics):\n",
    "            video_measurements[f\"avg_inner_{key}_{stat}\"] = results[i][j]\n",
    "    \n",
    "    # number of people, confidence and size of bounding boxes \n",
    "    results = calculate_nb_persons_statistics(keyframe_dir)\n",
    "    keys = ['nb', 'largest_confidence', 'avg_confidence', 'largest_bb', 'sum_of_bb']\n",
    "    statistics = ['mean', 'sd', 'vol']\n",
    "    for j, key in enumerate(keys):\n",
    "        for i, stat in enumerate(statistics):\n",
    "            video_measurements[f\"{key}_people_{stat}\"] = results[i][j]\n",
    "\n",
    "    # Number of faces, confidence and size of bounding boxes \n",
    "    results = calculate_nb_faces_statistics(keyframe_dir)\n",
    "    keys = ['nb', 'largest_confidence', 'avg_confidence', 'largest_bb', 'sum_of_bb']\n",
    "    statistics = ['mean', 'sd', 'vol']\n",
    "    for j, key in enumerate(keys):\n",
    "        for i, stat in enumerate(statistics):\n",
    "            video_measurements[f\"{key}_faces_{stat}\"] = results[i][j]\n",
    "\n",
    "    # Number of hands and size of bounding boxes \n",
    "    results = calculate_nb_hands_statistics(keyframe_dir)\n",
    "    keys = ['nb', 'largest_bb', 'sum_of_bb']\n",
    "    statistics = ['mean', 'sd', 'vol']\n",
    "    for j, key in enumerate(keys):\n",
    "        for i, stat in enumerate(statistics):\n",
    "            video_measurements[f\"{key}_hands_{stat}\"] = results[i][j]\n",
    "   \n",
    "    return video_measurements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28daa9ba-b32b-45a1-8041-3c508027be82",
   "metadata": {},
   "source": [
    "# Change the index, i, here to procces a new block of videos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be1b1dac-99ac-49b3-939a-bda8181d2ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1 # (integer): block 1-10 of each 2018 of 20180 the total videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b6379c5-05ac-4dce-8007-cbd48b2634cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting fresh, no previously processed videos found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [07:58<00:00,  4.79s/it]\n"
     ]
    }
   ],
   "source": [
    "# Try to load previously processed data, if it exists\n",
    "try:\n",
    "    processed_df = pd.read_csv(f\"visual_features_{i}.csv\")\n",
    "    processed_video_ids = set(processed_df[\"video_id\"].unique())\n",
    "    print(f\"Resuming from {len(processed_video_ids)} previously processed videos.\")\n",
    "except FileNotFoundError:\n",
    "    processed_video_ids = set()\n",
    "    print(\"Starting fresh, no previously processed videos found.\")\n",
    "    \n",
    "# List of measures to analyze (measure_name, measure_function, output_keys)\n",
    "measures = [\n",
    "    (\"color_warmth\", calculate_color_warmth, [\"mean\", \"sd\", \"vol\"]),\n",
    "    (\"valence\", calculate_valence_statistics, [\"mean\", \"sd\", \"vol\"]),\n",
    "    (\"dominance\", calculate_dominance_statistics, [\"mean\", \"sd\", \"vol\"]),\n",
    "    (\"arousal\", calculate_arousal_statistics, [\"mean\", \"sd\", \"vol\"]),\n",
    "    (\"colorfulness\", calculate_colorfulness_statistics, [\"mean\", \"sd\", \"vol\"]),\n",
    "    (\"clarity\", calculate_clarity_statistics, [\"mean\", \"sd\", \"vol\"]),\n",
    "    (\"gray_distribution_entropy\", calculate_gray_distribution_entropy_statistics, [\"mean\", \"sd\", \"vol\"]),\n",
    "    (\"blurriness\", calculate_blurriness_statistics, [\"mean\", \"median\", \"sd\", \"vol\"]),\n",
    "    (\"edge_points\", calculate_edge_points_statistics, [\"mean\", \"sd\", \"vol\"])\n",
    "]     \n",
    "\n",
    "keyframe_interval=10\n",
    "\n",
    "video_folder = '../../YouTube_Downloader/Complete_Downloads'\n",
    "keyframe_folder = f'Keyframes/{i}'\n",
    "files = os.listdir(video_folder)\n",
    "mp4_files = [file for file in files if file.endswith('.mp4')]\n",
    "\n",
    "    \n",
    "    # Iterate over the i'th block of .mp4 files in the directory\n",
    "for filename in tqdm(mp4_files[2018*(i-1):2018*(i)], total=2018): # section i/10 of the videos\n",
    "    video_path = os.path.join(video_folder, filename)\n",
    "    video_id = os.path.splitext(filename)[0]  # Get filename without extension\n",
    "\n",
    "    # Skip if video has already been processed\n",
    "    if video_id in processed_video_ids:\n",
    "        continue\n",
    "        \n",
    "    # Analyze video\n",
    "    video_analysis = analyse_video(video_id, video_folder, keyframe_folder, keyframe_interval=keyframe_interval, measures=measures)\n",
    "\n",
    "    # Append to the CSV, ensuring headers are written only once\n",
    "    df = pd.DataFrame([video_analysis])\n",
    "    df.to_csv(f\"visual_features_{i}.csv\", mode=\"a\", header=not bool(processed_video_ids), index=False)\n",
    "\n",
    "    # Add the processed video ID to the set\n",
    "    processed_video_ids.add(video_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
