{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2bb3e5a",
   "metadata": {},
   "source": [
    "# Motion Analysis Pipeline\n",
    "\n",
    "## Overview\n",
    "This Jupyter notebook implements a distributed video motion analysis pipeline. It processes videos in parallel across multiple instances, extracting motion-related features using optical flow and scene detection techniques.\n",
    "\n",
    "### Key Features\n",
    "- Distributed processing across multiple VMs\n",
    "- Optical flow analysis for motion tracking\n",
    "- Scene detection and shot analysis\n",
    "- Circular statistics for motion direction\n",
    "- Entropy-based feature extraction\n",
    "\n",
    "### Prerequisites\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d95f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scenedetect\n",
    "!pip install opencv-python\n",
    "!pip install scipy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from math import atan2, pi\n",
    "from scipy.stats import entropy\n",
    "from scenedetect import detect, AdaptiveDetector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88839800",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Motion Features Extracted\n",
    "- Motion magnitude (mean, std, volatility)\n",
    "- Motion direction (mean, std, volatility)\n",
    "- Spatial entropy (mean, std, volatility)\n",
    "- Information entropy (mean, std, volatility)\n",
    "- Shot detection rate (shots per minute)\n",
    "\n",
    "### Process Flow\n",
    "1. Split video list across instances\n",
    "2. Process each video in parallel:\n",
    "   - Extract frames at specified intervals\n",
    "   - Calculate optical flow\n",
    "   - Compute motion statistics\n",
    "   - Detect scene transitions\n",
    "3. Save results to instance-specific CSV files\n",
    "4. Merge results in post-processing\n",
    "\n",
    "### Usage\n",
    "Configure `num_instances` and `instance_id` for distributed processing. Results are saved to `motion_data_{instance_id}.csv` files for later merging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6592c0e8-78c8-434e-b6d3-39dc347093ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def circular_mean_std(angles):\n",
    "    sin_sum = np.sum(np.sin(angles))\n",
    "    cos_sum = np.sum(np.cos(angles))\n",
    "    mean_angle = atan2(sin_sum, cos_sum)\n",
    "    mean_angle = mean_angle if mean_angle >= 0 else mean_angle + 2 * pi\n",
    "    angular_deviation = np.sqrt(-2 * np.log(np.sqrt(sin_sum**2 + cos_sum**2) / len(angles)))\n",
    "    return mean_angle, angular_deviation\n",
    "\n",
    "def circular_volatility(angles):\n",
    "    diffs = np.diff(angles)\n",
    "    diffs = np.arctan2(np.sin(diffs), np.cos(diffs))  # Normalize differences\n",
    "    return np.std(diffs)\n",
    "\n",
    "def compute_entropy(image):\n",
    "    hist, _ = np.histogram(image.ravel(), bins=256, range=(0, 256), density=True)\n",
    "    return entropy(hist, base=2)\n",
    "\n",
    "def detect_shots(video_path):\n",
    "    detector = AdaptiveDetector()\n",
    "    scene_list = detect(str(video_path), detector)\n",
    "    cap = cv2.VideoCapture(str(video_path))\n",
    "    duration = cap.get(cv2.CAP_PROP_FRAME_COUNT) / cap.get(cv2.CAP_PROP_FPS)\n",
    "    cap.release()\n",
    "    return len(scene_list) / (duration / 60) if duration > 0 else 0\n",
    "\n",
    "def process_video(video_path, sampling_interval=1):\n",
    "    cap = cv2.VideoCapture(str(video_path))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    sample_frames = np.arange((fps * sampling_interval) // 2, frame_count, fps * sampling_interval)\n",
    "    \n",
    "    ret, prev_frame = cap.read()\n",
    "    if not ret:\n",
    "        cap.release()\n",
    "        return None\n",
    "    prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    magnitudes, angles, spatial_entropies, info_entropies = [], [], [], []\n",
    "    \n",
    "    for idx in sample_frames:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, idx)\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        flow = cv2.calcOpticalFlowFarneback(prev_gray, gray, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "        mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "        \n",
    "        magnitudes.append(np.mean(mag))\n",
    "        angles.append(np.mean(ang))\n",
    "        spatial_entropies.append(compute_entropy(gray))\n",
    "        info_entropies.append(compute_entropy(mag))\n",
    "        \n",
    "        prev_gray = gray\n",
    "    \n",
    "    cap.release()\n",
    "    \n",
    "    if not magnitudes:\n",
    "        return None\n",
    "    \n",
    "    angle_mean, angle_std = circular_mean_std(np.array(angles))\n",
    "    avg_shots_per_min = detect_shots(video_path)\n",
    "    \n",
    "    return {\n",
    "        'video_id': video_path.stem,\n",
    "        'file_name': video_path.stem,\n",
    "        'motion_magnitude_mean': np.mean(magnitudes),\n",
    "        'motion_magnitude_std': np.std(magnitudes),\n",
    "        'motion_magnitude_volatility': np.std(np.diff(magnitudes)),\n",
    "        'motion_direction_mean': angle_mean,\n",
    "        'motion_direction_std': angle_std,\n",
    "        'motion_direction_volatility': circular_volatility(np.array(angles)),\n",
    "        'spatial_entropy_mean': np.mean(spatial_entropies),\n",
    "        'spatial_entropy_std': np.std(spatial_entropies),\n",
    "        'spatial_entropy_volatility': np.std(np.diff(spatial_entropies)),\n",
    "        'info_entropy_mean': np.mean(info_entropies),\n",
    "        'info_entropy_std': np.std(info_entropies),\n",
    "        'info_entropy_volatility': np.std(np.diff(info_entropies)),\n",
    "        'avg_shots_per_min': avg_shots_per_min\n",
    "    }\n",
    "\n",
    "def split_video_list(video_files, num_splits):\n",
    "    \"\"\"Split video files into roughly equal parts.\"\"\"\n",
    "    return np.array_split(video_files, num_splits)\n",
    "\n",
    "def process_videos_subset(video_files, csv_path, motion_data_path, sampling_interval=1):\n",
    "    \"\"\"Process only a given subset of videos, checking both CSVs.\"\"\"\n",
    "    processed_videos = set()\n",
    "    \n",
    "    # Check the first CSV\n",
    "    if csv_path.exists():\n",
    "        df_existing = pd.read_csv(csv_path)\n",
    "        processed_videos.update(set(df_existing['video_id']))\n",
    "    \n",
    "    # Check the second CSV\n",
    "    if motion_data_path.exists():\n",
    "        df_motion_data = pd.read_csv(motion_data_path)\n",
    "        processed_videos.update(set(df_motion_data['video_id']))\n",
    "    \n",
    "    for video in video_files:\n",
    "        if video.stem in processed_videos:\n",
    "            continue\n",
    "        \n",
    "        result = process_video(video, sampling_interval)\n",
    "        if result:\n",
    "            df_new = pd.DataFrame([result])\n",
    "            df_new.to_csv(csv_path, mode='a', header=not csv_path.exists(), index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927a533a-362d-4244-ad3f-0ec0de871777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually specify parameters\n",
    "num_instances = 5  # Adjust this to match the number of VMs\n",
    "instance_id = 4  # Manually change this for each VM (0, 1, 2, ...)\n",
    "\n",
    "folder_path = Path('../../YouTube_Downloader/Complete_Downloads')\n",
    "all_videos = list(folder_path.glob('*.mp4'))\n",
    "csv_path = Path(f\"motion_data_{instance_id}.csv\")\n",
    "motion_data_path = Path(\"motion_data.csv\")\n",
    "\n",
    "\n",
    "\n",
    "# Split videos and select the subset for this instance\n",
    "video_chunks = split_video_list(all_videos, num_instances)\n",
    "\n",
    "if instance_id < len(video_chunks):\n",
    "    process_videos_subset(video_chunks[instance_id], csv_path, motion_data_path, sampling_interval=10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
