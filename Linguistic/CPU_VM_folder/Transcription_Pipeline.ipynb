{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ed7bbd5",
   "metadata": {},
   "source": [
    "# Video Transcription Pipeline\n",
    "\n",
    "## Overview\n",
    "This Jupyter notebook implements a batch processing pipeline for transcribing YouTube videos using OpenAI's Whisper model. It processes videos sequentially, saves transcripts, and tracks progress throughout the transcription process.\n",
    "\n",
    "### Key Features\n",
    "- Batch video transcription using Whisper-turbo model\n",
    "- Progress tracking and display\n",
    "- Error handling for corrupted files\n",
    "- CSV output with video IDs and transcripts\n",
    "- Resumable processing capability\n",
    "\n",
    "### Prerequisites\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8454eaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai-whisper pandas tqdm --break-system-packages\n",
    "!pip install ffmpeg-python --break-system-packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6387787",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import whisper\n",
    "import subprocess\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ca5ab7",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Configuration\n",
    "- Input: MP4 video files in `Non_Transcribed_Videos` folder\n",
    "- Output: Transcriptions saved to `Transcription.csv`\n",
    "- Model: Whisper-turbo for optimal speed/accuracy balance\n",
    "\n",
    "### Process Flow\n",
    "1. Load Whisper model and initialize settings\n",
    "2. Process videos sequentially:\n",
    "   - Extract audio and transcribe\n",
    "   - Save results to CSV\n",
    "   - Update progress display\n",
    "3. Handle errors and corrupted files\n",
    "4. Track completion percentage\n",
    "\n",
    "### Usage\n",
    "The pipeline expects videos in the `Non_Transcribed_Videos` folder and processes them sequentially, displaying progress as a percentage of total videos completed."
   ]
  },
  {
   "cell_type": "raw",
   "id": "76e2d100",
   "metadata": {},
   "source": [
    "input_folder = 'Non_Transcribed_Videos'\n",
    "output_folder = 'Transcription.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0110370-1052-4bb4-b1eb-df17805d8cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Whisper-turbo...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 1.51G/1.51G [00:52<00:00, 30.9MiB/s]\n"
     ]
    }
   ],
   "source": [
    "input_folder = 'Non_Transcribed_Videos'\n",
    "output_folder = 'Transcription.csv'\n",
    "print(\"Loading Whisper-turbo...\")\n",
    "model = whisper.load_model(\"turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f944207-fdbb-40f7-8543-5baba6de13b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "N = 10956 \n",
    "mp4_files = os.listdir(input_folder)\n",
    "\n",
    "# delete transcribed videos\n",
    "if os.path.exists(output_folder):\n",
    "        df = pd.read_csv(output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc66e9fd-0fe7-48eb-aba4-8cd39a560c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_progress():\n",
    "    clear_output(wait=True)\n",
    "    print(f\"{(N-len(mp4_files))/N * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5b5626e0-2a14-4c61-a496-a638dcaf0a45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def process_video(video):\n",
    "    video_path = os.path.join(input_folder, video)\n",
    "\n",
    "    try:\n",
    "        # Transcribe audio directly from MP4\n",
    "        result = model.transcribe(video_path)\n",
    "        transcript = result[\"text\"]\n",
    "\n",
    "        # Save result to CSV\n",
    "        video_id = os.path.splitext(video)[0]\n",
    "        df = pd.DataFrame([{\"Video ID\": video_id, \"transcript\": transcript}])\n",
    "        df.to_csv(output_folder, mode='a', header=not os.path.exists(output_folder), index=False)\n",
    "\n",
    "    except RuntimeError as e:\n",
    "        if \"moov atom not found\" in str(e) or \"Invalid data found when processing input\" in str(e):\n",
    "            print(f\"Skipping {video} due to file corruption or invalid format.\")\n",
    "        else:\n",
    "            raise  # Re-raise other errors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e072a9bb-ae2f-49e2-83f2-eafe61f4c75e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93.56%\n",
      "\n",
      " Processing video: 0Sum_pDOiyI ...\n"
     ]
    }
   ],
   "source": [
    "for video in mp4_files:\n",
    "    print(f\"\\n Processing video: {os.path.splitext(video)[0]} ...\")\n",
    "    process_video(video)\n",
    "    get_progress()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
